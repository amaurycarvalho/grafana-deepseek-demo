{
  "name": "mcp-bridge",
  "version": "1.3.0",
  "description": "Ollama (LLM) and MCP Server bridge to Grafana integration via OpenAI-compatible API.",
  "type": "module",
  "main": "index.js",
  "experimentalDecorators": true,
  "scripts": {
    "start": "node index.js",
    "dev": "nodemon index.js",
    "lint": "eslint . --ext .js,.mjs"
  },
  "dependencies": {
    "@opentelemetry/api": "^1.9.0",
    "@opentelemetry/auto-instrumentations-node": "^0.66.0",
    "@opentelemetry/exporter-trace-otlp-http": "^0.207.0",
    "@opentelemetry/instrumentation": "^0.207.0",
    "@opentelemetry/resources": "^2.2.0",
    "@opentelemetry/sdk-trace-base": "^2.2.0",
    "@opentelemetry/sdk-trace-node": "^2.2.0",
    "@opentelemetry/semantic-conventions": "^1.37.0",
    "@pyroscope/nodejs": "^0.4.5",
    "express": "^4.19.2",
    "node-fetch": "^3.3.2",
    "ollama": "^0.5.8",
    "prom-client": "^15.1.3",
    "typescript-eslint": "^8.46.2",
    "winston": "^3.15.0",
    "winston-loki": "^6.1.2"
  },
  "devDependencies": {
    "@eslint/js": "^9.37.0",
    "@typescript-eslint/eslint-plugin": "^8.46.2",
    "@typescript-eslint/parser": "^8.46.2",
    "eslint": "^9.37.0",
    "globals": "^16.4.0",
    "nodemon": "^3.1.7"
  },
  "engines": {
    "node": ">=18.0.0"
  }
}
